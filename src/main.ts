import './style.css'
import * as THREE from 'three';
import { GLTFLoader } from 'three/examples/jsm/loaders/GLTFLoader.js';
import { VRM, VRMLoaderPlugin } from '@pixiv/three-vrm';
import { FaceMesh } from '@mediapipe/face_mesh';

// --- è¨­å®š ---
const CANVAS_WIDTH = 480;
const CANVAS_HEIGHT = 360;

// --- 3Dã‚·ãƒ¼ãƒ³ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ— ---
const scene = new THREE.Scene();
const camera = new THREE.PerspectiveCamera(30, CANVAS_WIDTH / CANVAS_HEIGHT, 0.1, 20.0);
camera.position.set(0, 1.4, 1.5); // é¡”ã®æ­£é¢ã«ã‚«ãƒ¡ãƒ©ã‚’é…ç½®

// ğŸ’¡ ç¢ºå®Ÿã«è¦ç´ ã‚’å–å¾—ã™ã‚‹ãŸã‚ã« ! ã‚’ä½¿ç”¨
const canvas = document.querySelector('#local-canvas') as HTMLCanvasElement;
if (!canvas) throw new Error('Canvas element not found');

const renderer = new THREE.WebGLRenderer({ 
  canvas: canvas, 
  alpha: true, 
  antialias: true 
});
renderer.setSize(CANVAS_WIDTH, CANVAS_HEIGHT);
renderer.setPixelRatio(window.devicePixelRatio);

// ãƒ©ã‚¤ãƒˆã®è¨­å®š
const light = new THREE.DirectionalLight(0xffffff, Math.PI);
light.position.set(1, 1, 1).normalize();
scene.add(light);

// --- VRMãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ ---
let currentVrm: VRM | null = null;
const loader = new GLTFLoader();
loader.register((parser) => new VRMLoaderPlugin(parser));

// publicãƒ•ã‚©ãƒ«ãƒ€ã«ã€Œã‚­ãƒ„ãƒã®é¡”.vrmã€ã‚’ç½®ã„ã¦ã„ã‚‹å‰æ
loader.load(
  '/ã‚­ãƒ„ãƒã®é¡”.vrm', 
  (gltf) => {
    const vrm = gltf.userData.vrm as VRM;
    currentVrm = vrm;
    scene.add(vrm.scene);
    vrm.scene.rotation.y = Math.PI; // ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å‘ãåˆã‚ã›ã‚‹
    console.log('VRM model loaded');
  },
  (progress) => console.log('Loading VRM...', (progress.loaded / progress.total * 100), '%'),
  (error) => console.error('VRM load error:', error)
);

// --- MediaPipe FaceMesh è¨­å®š ---
const video = document.querySelector('#hidden-video') as HTMLVideoElement;
if (!video) throw new Error('Video element not found');

const faceMesh = new FaceMesh({ 
  locateFile: (f) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${f}` 
});
faceMesh.setOptions({ 
  maxNumFaces: 1, 
  refineLandmarks: true,
  minDetectionConfidence: 0.5,
  minTrackingConfidence: 0.5
});

// AIè§£æçµæœã‚’VRMã«åæ˜ 
faceMesh.onResults((res) => {
  if (currentVrm && res.multiFaceLandmarks?.[0]) {
    const s = res.multiFaceLandmarks[0];

    // 1. é¦–ã®å›è»¢é€£å‹• (Head Rotation)
    const head = currentVrm.humanoid.getRawBoneNode('head');
    if (head) {
      // å·¦å³ (Yaw), ä¸Šä¸‹ (Pitch), å‚¾ã (Roll) ã‚’è¨ˆç®—
      head.rotation.y = (s[234].x - s[454].x) * 0.5;
      head.rotation.x = (s[10].y - s[152].y) * 0.5;
      head.rotation.z = Math.atan2(s[263].y - s[33].y, s[263].x - s[33].x);
    }

    // 2. ã¾ã°ãŸãé€£å‹• (Blink)
    if (currentVrm.expressionManager) {
      const eyeScore = Math.abs(s[159].y - s[145].y);
      const blink = eyeScore < 0.012 ? 1.0 : 0.0;
      currentVrm.expressionManager.setValue('blink', blink);
    }

    // 3. å£ãƒ‘ã‚¯é€£å‹• (Mouth - "aa")
    if (currentVrm.expressionManager) {
      const mouthScore = Math.abs(s[13].y - s[14].y);
      // è·é›¢ã«å¿œã˜ã¦å£ã®é–‹ãå…·åˆã‚’0.0ã€œ1.0ã§èª¿æ•´
      currentVrm.expressionManager.setValue('aa', Math.min(mouthScore * 12, 1.0));
    }

    // ãƒ¢ãƒ‡ãƒ«ã®å†…éƒ¨çŠ¶æ…‹ã‚’æ›´æ–°
    currentVrm.update(1/30);
  }
  // 3Dãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°
  renderer.render(scene, camera);
});

// --- ã‚«ãƒ¡ãƒ©èµ·å‹• & ãƒ«ãƒ¼ãƒ—é–‹å§‹ ---
const startCamera = async () => {
  try {
    const stream = await navigator.mediaDevices.getUserMedia({ 
      video: { width: CANVAS_WIDTH, height: CANVAS_HEIGHT } 
    });
    video.srcObject = stream;
    
    video.onloadedmetadata = () => {
      video.play();
      const loop = async () => {
        // ãƒ“ãƒ‡ã‚ªãŒæœ‰åŠ¹ãªæ™‚ã ã‘AIã«é€ã‚‹
        if (video.readyState >= 2) {
          await faceMesh.send({ image: video });
        }
        requestAnimationFrame(loop);
      };
      loop();
    };
  } catch (err) {
    console.error("Camera error:", err);
    alert("ã‚«ãƒ¡ãƒ©ã®èµ·å‹•ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚«ãƒ¡ãƒ©ã®ä½¿ç”¨ã‚’è¨±å¯ã—ã¦ãã ã•ã„ã€‚");
  }
};

startCamera();